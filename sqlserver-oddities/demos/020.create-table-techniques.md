# SQL Server Tips & Tricks: Techniques in `020.create-table.sql`

This demo showcases several advanced SQL Server techniques for dynamic table creation, string manipulation, and metadata exploration. Below is a detailed explanation of each technique used in the script, designed for the SQL Server Tips and Tricks Community Presentation.

---

## 1. Dynamic Column List with Variables


```sql
DECLARE @cols varchar(max) = '<complaint-id>, <attendee-id>, ...';
```

- **Purpose:** Store a list of column names in a single variable for dynamic processing.
- **Tip:** Useful for generating dynamic SQL or iterating over column definitions.

**Explanation:**
Using a variable to hold a delimited list of column names is a powerful technique for dynamic SQL generation. It allows you to centralize schema definitions, making it easy to update or extend the list without modifying multiple code locations. This approach is especially useful in automation, ETL, or metadata-driven scenarios, where table structures may change or be generated on the fly. It also enables you to iterate over columns programmatically, reducing manual effort and errors.

**SQL Server Version:**
Variable assignment with `DECLARE` is available in all supported SQL Server versions (since SQL Server 2000 and earlier).

---

## 2. String Splitting and Manipulation


### Using `STRING_SPLIT`
```sql
SELECT * FROM STRING_SPLIT(@cols, '>, <')
```

- **Purpose:** Split a delimited string into rows.
- **Limitation:** The built-in `STRING_SPLIT` only supports single-character delimiters, so the demo uses a workaround with `', '` as the separator.

**Explanation:**
Splitting a delimited string into rows lets you process each column name individually. While SQL Server's `STRING_SPLIT` is limited to single-character delimiters, you can format your input string and delimiter to work around this. This technique is essential for converting a flat list into a tabular format, enabling further manipulation, cleaning, or analysis of each column name. It is a common pattern in dynamic SQL and metadata-driven development.

**SQL Server Version:**
`STRING_SPLIT` is available starting with SQL Server 2016 (compatibility level 130+).

### Using `TRANSLATE` and `TRIM`
```sql
TRANSLATE(TRIM(' <>' FROM cols.value), '-#', '__')
```

- **Purpose:**
  - `TRIM`: Removes unwanted characters (spaces, angle brackets) from column names.
  - `TRANSLATE`: Replaces specific characters (`-`, `#`) with underscores for valid SQL identifiers.
- **Tip:** Ensures column names are clean and SQL-compliant.

**Explanation:**
`TRIM` is used to remove leading and trailing spaces or special characters, ensuring that each column name is clean and free of formatting artifacts. `TRANSLATE` replaces problematic characters (like hyphens or hash signs) with underscores, which are valid in SQL identifiers. This step is crucial for generating valid table or column names dynamically, preventing syntax errors and improving code reliability. It also helps enforce naming conventions and avoid conflicts with reserved keywords.

**SQL Server Version:**
`TRANSLATE` and `TRIM` are available starting with SQL Server 2017 (compatibility level 140+).

---

## 3. Metadata Exploration with `sys.dm_exec_describe_first_result_set`


```sql
OUTER APPLY sys.dm_exec_describe_first_result_set(CONCAT('CREATE TABLE ', col ,' (id int)'), NULL, 0) rs
```

- **Purpose:** Dynamically inspects the structure of a hypothetical table to determine column metadata.
- **Tip:** Useful for validating or inferring column properties before actual table creation.

**Explanation:**
This technique leverages SQL Server's metadata functions to analyze the result set of a dynamically constructed SQL statement. By simulating a table creation, you can inspect how SQL Server interprets the column definition, which helps in validating column names, types, and other properties before actually creating the table. This is especially useful in automation, code generation, or schema validation scenarios. It allows you to catch errors early and ensure that your dynamic SQL will execute successfully.

**SQL Server Version:**
`sys.dm_exec_describe_first_result_set` is available starting with SQL Server 2012.

---

## 4. Conditional Column Name Transformation


```sql
CONCAT(CHOOSE(to_change, 'complaint_'), col)
```

- **Purpose:** Conditionally prefixes column names based on metadata analysis.
- **Tip:** Automates naming conventions for consistency.

**Explanation:**
Using conditional logic to transform column names ensures that your schema follows consistent naming conventions. The `CHOOSE` function allows you to select a prefix or transformation based on metadata or other criteria, making your code adaptable to different requirements. This technique is valuable for enforcing standards, avoiding naming conflicts, and improving code readability. It also helps automate repetitive tasks and reduces manual intervention in schema design.

**SQL Server Version:**
`CHOOSE` is available starting with SQL Server 2012.

---

## 5. Data Type Inference with Regular Expressions


```sql
LEFT JOIN (VALUES('.*_(id|type|level|order)$','INT', 1), ... ) v(s, t, pref) ON REGEXP_LIKE(c.col, v.s)
```

- **Purpose:** Assigns data types to columns based on their names using regex patterns.
- **Tip:** Streamlines schema generation by automating type assignment.
- **Note:** Requires compatibility level 160+ for `REGEXP_LIKE`.

**Explanation:**
By using regular expressions to match column name patterns, you can automatically infer the most appropriate data type for each column. For example, columns ending in `_id` or `_type` are likely to be integers, while those ending in `_name` or `_email` are typically strings. This approach reduces manual effort, minimizes errors, and ensures consistency across dynamically generated schemas. The use of `REGEXP_LIKE` makes the matching flexible and powerful, but requires SQL Server 2022 or later. This technique is especially useful in environments with evolving or unpredictable schemas.

**SQL Server Version:**
`REGEXP_LIKE` is available starting with SQL Server 2022 (compatibility level 160+).

---

## 6. Window Functions for Column Selection


```sql
FIRST_VALUE(CONCAT_WS(' ', col, v.t)) OVER (PARTITION BY col ORDER BY pref)
```

- **Purpose:** Selects the most appropriate data type for each column using window functions.
- **Tip:** Ensures the best match for each column based on priority.

**Explanation:**
Window functions like `FIRST_VALUE` allow you to select the highest-priority match for each column, even when multiple patterns could apply. By partitioning by column and ordering by preference, you ensure that the most relevant data type or transformation is chosen. This technique is essential for resolving ambiguities and automating complex decision logic in dynamic SQL generation. It helps you build robust, adaptable code that can handle a variety of input scenarios.

**SQL Server Version:**
Window functions such as `FIRST_VALUE` and `PARTITION BY` are available starting with SQL Server 2012.

---

## 7. Dynamic SQL Table Definition Generation


```sql
CONCAT('CREATE TABLE dbo complaint', TRIM(', ' + CHAR(13) FROM STRING_AGG(col, ', ' + CHAR(13)) ...))
```

- **Purpose:** Assembles the final `CREATE TABLE` statement dynamically from processed column definitions.
- **Tip:** Enables flexible, automated table creation from a simple column list.

**Explanation:**
By aggregating the processed column definitions into a single string, you can generate a complete `CREATE TABLE` statement on the fly. This approach is highly flexible, allowing you to build tables based on metadata, user input, or other dynamic sources. It is particularly useful in automation, rapid prototyping, and environments where schemas change frequently. This technique also helps ensure that your DDL statements are always up-to-date with your metadata.

**SQL Server Version:**
`STRING_AGG` is available starting with SQL Server 2017 (compatibility level 140+). `CONCAT` is available since SQL Server 2012. `TRIM` is available since SQL Server 2017.

---

## 8. Comments and Compatibility Notes


- **Inline Comments:** Explain shortcuts, limitations, and compatibility requirements (e.g., for `REGEXP_LIKE`).
- **Tip:** Always document assumptions and requirements for future maintainers.

**Explanation:**
Well-placed comments and notes in your SQL scripts help others understand the logic, limitations, and requirements of your code. This is especially important when using advanced features or relying on specific SQL Server versions. Documenting shortcuts, workarounds, and compatibility issues ensures that your code is maintainable and easier to troubleshoot or extend in the future. Good documentation is a hallmark of professional development and helps foster collaboration.

**SQL Server Version:**
Comments are supported in all SQL Server versions. For compatibility notes, always check the minimum required version for each feature used in your scripts.

---

## Summary Table of Techniques

| Technique                        | SQL Feature(s) Used                | Purpose/Benefit                  |
|----------------------------------|------------------------------------|----------------------------------|
| Dynamic column list              | Variable assignment                | Flexible schema generation       |
| String splitting/manipulation    | `STRING_SPLIT`, `TRIM`, `TRANSLATE`| Clean, parse column names        |
| Metadata exploration             | `sys.dm_exec_describe_first_result_set` | Validate column structure   |
| Conditional transformation       | `CHOOSE`, `CONCAT`                 | Consistent naming conventions    |
| Data type inference              | `REGEXP_LIKE`, `VALUES`            | Automated type assignment        |
| Window functions                 | `FIRST_VALUE`, `PARTITION BY`      | Best match selection             |
| Dynamic SQL generation           | `STRING_AGG`, `CONCAT`, `TRIM`     | Automated DDL creation           |
| Documentation                    | Inline comments                    | Maintainability                  |

---

## References
- [STRING_SPLIT (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/functions/string-split-transact-sql)
- [TRANSLATE (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/functions/translate-transact-sql)
- [TRIM (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/functions/trim-transact-sql)
- [sys.dm_exec_describe_first_result_set](https://learn.microsoft.com/en-us/sql/relational-databases/system-dynamic-management-views/sys-dm-exec-describe-first-result-set-transact-sql)
- [REGEXP_LIKE (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/functions/regexp-like-transact-sql)

---

This demo is a great example of how to leverage SQL Server's advanced features for dynamic, maintainable, and automated schema generation. Each technique can be adapted for broader use in real-world database development.
